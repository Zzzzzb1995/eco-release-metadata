<!---
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<h1 id="apache-hbase-0.98.18-release-notes">Apache HBase 0.98.18 Release Notes</h1>
<p>These release notes cover new developer and user-facing incompatibilities, important issues, features, and major improvements.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15111">HBASE-15111</a> | <em>Trivial</em> | <strong>&quot;hbase version&quot; should write to stdout</strong></li>
</ul>
<p>The <code>hbase version</code> command now outputs directly to stdout rather than to a logger. This change allows the version information to be output consistently regardless of logger configuration. Naturally, this also means the command output ignores all logger configuration. Furthermore, the move from loggers to direct output changes the output of the command to omit metadata commonly included in logger ouput such as a timestamp, log level, and logger name.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15125">HBASE-15125</a> | <em>Major</em> | <strong>HBaseFsck's adoptHdfsOrphan function creates region with wrong end key boundary</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this change.</strong></p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15145">HBASE-15145</a> | <em>Major</em> | <strong>HBCK and Replication should authenticate to zookepeer using server principal</strong></li>
</ul>
<p>Added a new command line argument: --auth-as-server to enable authenticating to ZooKeeper as the HBase Server principal. This is required for secure clusters for doing replication operations like add_peer, list_peers, etc until HBASE-11392 is fixed. This advanced option can also be used for manually fixing secure znodes.</p>
<p>Commands can now be invoked like: hbase --auth-as-server shell hbase --auth-as-server zkcli</p>
<p>HBCK in secure setup also needs to authenticate to ZK using servers principals.This is turned on by default (no need to pass additional argument).</p>
<p>When authenticating as server, HBASE_SERVER_JAAS_OPTS is concatenated to HBASE_OPTS if defined in hbase-env.sh. Otherwise, HBASE_REGIONSERVER_OPTS is concatenated.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15129">HBASE-15129</a> | <em>Major</em> | <strong>Set default value for hbase.fs.tmp.dir rather than fully depend on hbase-default.xml</strong></li>
</ul>
<p>Before HBASE-15129, if somehow hbase-default.xml is not on classpath, default values for hbase.fs.tmp.dir and hbase.bulkload.staging.dir are left empty. After HBASE-15129, default values of both properties are set to &quot;/user/&lt;user.name&gt;/hbase-staging&quot;.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15218">HBASE-15218</a> | <em>Blocker</em> | <strong>On RS crash and replay of WAL, loosing all Tags in Cells</strong></li>
</ul>
<p>This issue fixes - In case of normal WAL (Not encrypted) we were loosing all cell tags on WAL replay after an RS crash - In case of encrypted WAL we were not even persisting Cell tags in WAL. Tags from all unflushed (to HFile) Cells will get lost even after WAL replay recovery is done.</p>
<p>As we use tags for Cell level security, this fixes 2 security issues - Cell level visibility labels security breach . Making a visibility restricted cell global readable - Cell level ACL availability issue. A user who is cell level authorized to read this cell can not read it. It is a data loss for him.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15219">HBASE-15219</a> | <em>Critical</em> | <strong>Canary tool does not return non-zero exit code when one of regions is in stuck state</strong></li>
</ul>
<p>A new flag is added for Canary tool: -treatFailureAsError When this flag is specified, read / write failure would result in Canary tool exit code of 5.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15290">HBASE-15290</a> | <em>Major</em> | <strong>Hbase Rest CheckAndAPI should save other cells along with compared cell</strong></li>
</ul>
<p>Fixed an issue in REST server checkAndPut operation where the remaining cells other than the to-be-checked column are also applied in the put operation .</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15181">HBASE-15181</a> | <em>Major</em> | <strong>A simple implementation of date based tiered compaction</strong></li>
</ul>
<p>Date tiered compaction policy is a date-aware store file layout that is beneficial for time-range scans for time-series data.</p>
<p>When it performs well:</p>
<pre><code>reads for limited time ranges, especially scans of recent data</code></pre>
<p>When it doesn't perform as well:</p>
<pre><code>random gets without a time range
frequent deletes and updates
out of order data writes, especially writes with timestamps in the future
bulk loads of historical data</code></pre>
<p>Recommended configuration: To turn on Date Tiered Compaction (It is not recommended to turn on for the whole cluster because that will put meta table on it too and random get on meta table will be impacted): hbase.hstore.compaction.compaction.policy: org.apache.hadoop.hbase.regionserver.compactions.DateTieredCompactionPolicy</p>
<p>Parameters for Date Tiered Compaction: hbase.hstore.compaction.date.tiered.max.storefile.age.millis: Files with max-timestamp smaller than this will no longer be compacted.Default at Long.MAX_VALUE. hbase.hstore.compaction.date.tiered.base.window.millis: base window size in milliseconds. Default at 6 hours. hbase.hstore.compaction.date.tiered.windows.per.tier: number of windows per tier. Default at 4. hbase.hstore.compaction.date.tiered.incoming.window.min: minimal number of files to compact in the incoming window. Set it to expected number of files in the window to avoid wasteful compaction. Default at 6. hbase.hstore.compaction.date.tiered.window.policy.class: the policy to select store files within the same time window. It doesnâ€™t apply to the incoming window. Default at exploring compaction. This is to avoid wasteful compaction.</p>
<p>With tiered compaction all servers in the cluster will promote windows to higher tier at the same time, so using a compaction throttle is recommended: hbase.regionserver.throughput.controller:org.apache.hadoop.hbase.regionserver.compactions.PressureAwareCompactionThroughputController</p>
<p>Because there will most likely be more store files around, we need to adjust the configuration so that flush won't be blocked and compaction will be properly throttled: hbase.hstore.blockingStoreFiles: change to 50 if using all default parameters when turning on date tiered compaction. Use 1.5~2 x projected file count if changing the parameters, Projected file count = windows per tier x tier count + incoming window min + files older than max age</p>
<p>For more details, please refer to the design spec at https://docs.google.com/document/d/1_AmlNb2N8Us1xICsTeGDLKIqL6T-oHoRLZ323MG_uy8/edit#</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15435">HBASE-15435</a> | <em>Major</em> | <strong>Add WAL (in bytes) written metric</strong></li>
</ul>
<p>Adds a new metric named &quot;writtenBytes&quot; as a per-regionserver metric. Metric Description: Size (in bytes) of the data written to the WAL.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15323">HBASE-15323</a> | <em>Major</em> | <strong>Hbase Rest CheckAndDeleteAPi should be able to delete more cells</strong></li>
</ul>
<p>Fixed an issue in REST server checkAndDelete operation where the remaining cells other than the to-be-checked column are also applied in the Delete operation. Also fixed an issue in RemoteHTable where the Delete object was not passed correctly to the REST server side.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15430">HBASE-15430</a> | <em>Critical</em> | <strong>Failed taking snapshot - Manifest proto-message too large</strong></li>
</ul>
<p>Failed taking snapshot - Manifest proto-message too large. add property (&quot;snapshot.manifest.size.limit&quot;) to change max size of proto-message</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-12940">HBASE-12940</a> | <em>Major</em> | <strong>Expose listPeerConfigs and getPeerConfig to the HBase shell</strong></li>
</ul>
<p>Adds get_peer_config and list_peer_configs to the hbase shell.</p>
<hr />
<ul>
<li><a href="https://issues.apache.org/jira/browse/HBASE-15322">HBASE-15322</a> | <em>Critical</em> | <strong>Operations using Unsafe path broken for platforms not having sun.misc.Unsafe</strong></li>
</ul>
<p><strong>WARNING: No release note provided for this change.</strong></p>
